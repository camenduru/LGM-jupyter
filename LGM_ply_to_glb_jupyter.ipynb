{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/LGM-jupyter/blob/main/LGM_ply_to_glb_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone --recursive -b dev https://github.com/camenduru/LGM\n",
        "%cd /content/LGM\n",
        "\n",
        "!pip install -q tyro diffusers dearpygui einops accelerate lpips pygltflib rembg[gpu,cli] trimesh kiui xatlas roma plyfile\n",
        "!pip install -q https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl\n",
        "!pip install -q git+https://github.com/graphdeco-inria/diff-gaussian-rasterization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tyro\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from core.options import AllConfigs, Options\n",
        "from core.gs import GaussianRenderer\n",
        "\n",
        "import mcubes\n",
        "import nerfacc\n",
        "import nvdiffrast.torch as dr\n",
        "\n",
        "import kiui\n",
        "from kiui.mesh import Mesh\n",
        "from kiui.mesh_utils import clean_mesh, decimate_mesh\n",
        "from kiui.mesh_utils import laplacian_smooth_loss, normal_consistency\n",
        "from kiui.op import uv_padding, safe_normalize, inverse_sigmoid\n",
        "from kiui.cam import orbit_camera, get_perspective\n",
        "from kiui.nn import MLP, trunc_exp\n",
        "from kiui.gridencoder import GridEncoder\n",
        "\n",
        "def get_rays(pose, h, w, fovy, opengl=True):\n",
        "    \n",
        "    x, y = torch.meshgrid(\n",
        "        torch.arange(w, device=pose.device),\n",
        "        torch.arange(h, device=pose.device),\n",
        "        indexing=\"xy\",\n",
        "    )\n",
        "    x = x.flatten()\n",
        "    y = y.flatten()\n",
        "\n",
        "    cx = w * 0.5\n",
        "    cy = h * 0.5\n",
        "    focal = h * 0.5 / np.tan(0.5 * np.deg2rad(fovy))\n",
        "\n",
        "    camera_dirs = F.pad(\n",
        "        torch.stack(\n",
        "            [\n",
        "                (x - cx + 0.5) / focal,\n",
        "                (y - cy + 0.5) / focal * (-1.0 if opengl else 1.0),\n",
        "            ],\n",
        "            dim=-1,\n",
        "        ),\n",
        "        (0, 1),\n",
        "        value=(-1.0 if opengl else 1.0),\n",
        "    )  # [hw, 3]\n",
        "\n",
        "    rays_d = camera_dirs @ pose[:3, :3].transpose(0, 1)  # [hw, 3]\n",
        "    rays_o = pose[:3, 3].unsqueeze(0).expand_as(rays_d) # [hw, 3]\n",
        "\n",
        "    rays_d = safe_normalize(rays_d)\n",
        "\n",
        "    return rays_o, rays_d\n",
        "\n",
        "# Triple renderer of gaussians, gaussian, and diso mesh.\n",
        "# gaussian --> nerf --> mesh\n",
        "class Converter(nn.Module):\n",
        "    def __init__(self, opt: Options):\n",
        "        super().__init__()\n",
        "\n",
        "        self.opt = opt\n",
        "        self.device = torch.device(\"cuda\")\n",
        "\n",
        "        # gs renderer\n",
        "        self.tan_half_fov = np.tan(0.5 * np.deg2rad(opt.fovy))\n",
        "        self.proj_matrix = torch.zeros(4, 4, dtype=torch.float32, device=self.device)\n",
        "        self.proj_matrix[0, 0] = 1 / self.tan_half_fov\n",
        "        self.proj_matrix[1, 1] = 1 / self.tan_half_fov\n",
        "        self.proj_matrix[2, 2] = (opt.zfar + opt.znear) / (opt.zfar - opt.znear)\n",
        "        self.proj_matrix[3, 2] = - (opt.zfar * opt.znear) / (opt.zfar - opt.znear)\n",
        "        self.proj_matrix[2, 3] = 1\n",
        "\n",
        "        self.gs_renderer = GaussianRenderer(opt)\n",
        "\n",
        "        self.gaussians = self.gs_renderer.load_ply(opt.test_path).to(self.device)\n",
        "\n",
        "        # nerf renderer\n",
        "        if not self.opt.force_cuda_rast:\n",
        "            self.glctx = dr.RasterizeGLContext()\n",
        "        else:\n",
        "            self.glctx = dr.RasterizeCudaContext()\n",
        "        \n",
        "        self.step = 0\n",
        "        self.render_step_size = 5e-3\n",
        "        self.aabb = torch.tensor([-1.0, -1.0, -1.0, 1.0, 1.0, 1.0], device=self.device)\n",
        "        self.estimator = nerfacc.OccGridEstimator(roi_aabb=self.aabb, resolution=64, levels=1)\n",
        "\n",
        "        self.encoder_density = GridEncoder(num_levels=12) # VMEncoder(output_dim=16, mode='sum')\n",
        "        self.encoder = GridEncoder(num_levels=12)\n",
        "        self.mlp_density = MLP(self.encoder_density.output_dim, 1, 32, 2, bias=False)\n",
        "        self.mlp = MLP(self.encoder.output_dim, 3, 32, 2, bias=False)\n",
        "\n",
        "        # mesh renderer\n",
        "        self.proj = torch.from_numpy(get_perspective(self.opt.fovy)).float().to(self.device)\n",
        "        self.v = self.f = None\n",
        "        self.vt = self.ft = None\n",
        "        self.deform = None\n",
        "        self.albedo = None\n",
        "        \n",
        "       \n",
        "    @torch.no_grad()\n",
        "    def render_gs(self, pose):\n",
        "    \n",
        "        cam_poses = torch.from_numpy(pose).unsqueeze(0).to(self.device)\n",
        "        cam_poses[:, :3, 1:3] *= -1 # invert up & forward direction\n",
        "        \n",
        "        # cameras needed by gaussian rasterizer\n",
        "        cam_view = torch.inverse(cam_poses).transpose(1, 2) # [V, 4, 4]\n",
        "        cam_view_proj = cam_view @ self.proj_matrix # [V, 4, 4]\n",
        "        cam_pos = - cam_poses[:, :3, 3] # [V, 3]\n",
        "        \n",
        "        out = self.gs_renderer.render(self.gaussians.unsqueeze(0), cam_view.unsqueeze(0), cam_view_proj.unsqueeze(0), cam_pos.unsqueeze(0))\n",
        "        image = out['image'].squeeze(1).squeeze(0) # [C, H, W]\n",
        "        alpha = out['alpha'].squeeze(2).squeeze(1).squeeze(0) # [H, W]\n",
        "\n",
        "        return image, alpha\n",
        "\n",
        "    def get_density(self, xs):\n",
        "        # xs: [..., 3]\n",
        "        prefix = xs.shape[:-1]\n",
        "        xs = xs.view(-1, 3)\n",
        "        feats = self.encoder_density(xs)\n",
        "        density = trunc_exp(self.mlp_density(feats))\n",
        "        density = density.view(*prefix, 1)\n",
        "        return density\n",
        "    \n",
        "    def render_nerf(self, pose):\n",
        "        \n",
        "        pose = torch.from_numpy(pose.astype(np.float32)).to(self.device)\n",
        "        \n",
        "        # get rays\n",
        "        resolution = self.opt.output_size\n",
        "        rays_o, rays_d = get_rays(pose, resolution, resolution, self.opt.fovy)\n",
        "        \n",
        "        # update occ grid\n",
        "        if self.training:\n",
        "            def occ_eval_fn(xs):\n",
        "                sigmas = self.get_density(xs)\n",
        "                return self.render_step_size * sigmas\n",
        "            \n",
        "            self.estimator.update_every_n_steps(self.step, occ_eval_fn=occ_eval_fn, occ_thre=0.01, n=8)\n",
        "            self.step += 1\n",
        "\n",
        "        # render\n",
        "        def sigma_fn(t_starts, t_ends, ray_indices):\n",
        "            t_origins = rays_o[ray_indices]\n",
        "            t_dirs = rays_d[ray_indices]\n",
        "            xs = t_origins + t_dirs * (t_starts + t_ends)[:, None] / 2.0\n",
        "            sigmas = self.get_density(xs)\n",
        "            return sigmas.squeeze(-1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ray_indices, t_starts, t_ends = self.estimator.sampling(\n",
        "                rays_o,\n",
        "                rays_d,\n",
        "                sigma_fn=sigma_fn,\n",
        "                near_plane=0.01,\n",
        "                far_plane=100,\n",
        "                render_step_size=self.render_step_size,\n",
        "                stratified=self.training,\n",
        "                cone_angle=0,\n",
        "            )\n",
        "\n",
        "        t_origins = rays_o[ray_indices]\n",
        "        t_dirs = rays_d[ray_indices]\n",
        "        xs = t_origins + t_dirs * (t_starts + t_ends)[:, None] / 2.0\n",
        "        sigmas = self.get_density(xs).squeeze(-1)\n",
        "        rgbs = torch.sigmoid(self.mlp(self.encoder(xs)))\n",
        "\n",
        "        n_rays=rays_o.shape[0]\n",
        "        weights, trans, alphas = nerfacc.render_weight_from_density(t_starts, t_ends, sigmas, ray_indices=ray_indices, n_rays=n_rays)\n",
        "        color = nerfacc.accumulate_along_rays(weights, values=rgbs, ray_indices=ray_indices, n_rays=n_rays)\n",
        "        alpha = nerfacc.accumulate_along_rays(weights, values=None, ray_indices=ray_indices, n_rays=n_rays)\n",
        "\n",
        "        color = color + 1 * (1.0 - alpha)\n",
        "\n",
        "        color = color.view(resolution, resolution, 3).clamp(0, 1).permute(2, 0, 1).contiguous()\n",
        "        alpha = alpha.view(resolution, resolution).clamp(0, 1).contiguous()\n",
        "        \n",
        "        return color, alpha\n",
        "\n",
        "    def fit_nerf(self, iters=512, resolution=128):\n",
        "\n",
        "        self.opt.output_size = resolution\n",
        "\n",
        "        optimizer = torch.optim.Adam([\n",
        "            {'params': self.encoder_density.parameters(), 'lr': 1e-2},\n",
        "            {'params': self.encoder.parameters(), 'lr': 1e-2},\n",
        "            {'params': self.mlp_density.parameters(), 'lr': 1e-3},\n",
        "            {'params': self.mlp.parameters(), 'lr': 1e-3},\n",
        "        ])\n",
        "\n",
        "        print(f\"[INFO] fitting nerf...\")\n",
        "        pbar = tqdm.trange(iters)\n",
        "        for i in pbar:\n",
        "\n",
        "            ver = np.random.randint(-45, 45)\n",
        "            hor = np.random.randint(-180, 180)\n",
        "            rad = np.random.uniform(1.5, 3.0)\n",
        "            \n",
        "            pose = orbit_camera(ver, hor, rad)\n",
        "            \n",
        "            image_gt, alpha_gt = self.render_gs(pose)\n",
        "            image_pred, alpha_pred = self.render_nerf(pose)\n",
        "\n",
        "            # if i % 200 == 0:\n",
        "            #     kiui.vis.plot_image(image_gt, alpha_gt, image_pred, alpha_pred)\n",
        "            \n",
        "            loss_mse = F.mse_loss(image_pred, image_gt) + 0.1 * F.mse_loss(alpha_pred, alpha_gt)\n",
        "            loss = loss_mse #+ 0.1 * self.encoder_density.tv_loss() #+ 0.0001 * self.encoder_density.density_loss()\n",
        "\n",
        "            loss.backward()\n",
        "            self.encoder_density.grad_total_variation(1e-8)\n",
        "        \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pbar.set_description(f\"MSE = {loss_mse.item():.6f}\")\n",
        "        \n",
        "        print(f\"[INFO] finished fitting nerf!\")\n",
        "    \n",
        "    def render_mesh(self, pose):\n",
        "\n",
        "        h = w = self.opt.output_size\n",
        "\n",
        "        v = self.v + self.deform\n",
        "        f = self.f\n",
        "\n",
        "        pose = torch.from_numpy(pose.astype(np.float32)).to(v.device)\n",
        "\n",
        "        # get v_clip and render rgb\n",
        "        v_cam = torch.matmul(F.pad(v, pad=(0, 1), mode='constant', value=1.0), torch.inverse(pose).T).float().unsqueeze(0)\n",
        "        v_clip = v_cam @ self.proj.T\n",
        "\n",
        "        rast, rast_db = dr.rasterize(self.glctx, v_clip, f, (h, w))\n",
        "\n",
        "        alpha = torch.clamp(rast[..., -1:], 0, 1).contiguous() # [1, H, W, 1]\n",
        "        alpha = dr.antialias(alpha, rast, v_clip, f).clamp(0, 1).squeeze(-1).squeeze(0) # [H, W] important to enable gradients!\n",
        "        \n",
        "        if self.albedo is None:\n",
        "            xyzs, _ = dr.interpolate(v.unsqueeze(0), rast, f) # [1, H, W, 3]\n",
        "            xyzs = xyzs.view(-1, 3)\n",
        "            mask = (alpha > 0).view(-1)\n",
        "            image = torch.zeros_like(xyzs, dtype=torch.float32)\n",
        "            if mask.any():\n",
        "                masked_albedo = torch.sigmoid(self.mlp(self.encoder(xyzs[mask].detach(), bound=1)))\n",
        "                image[mask] = masked_albedo.float()\n",
        "        else:\n",
        "            texc, texc_db = dr.interpolate(self.vt.unsqueeze(0), rast, self.ft, rast_db=rast_db, diff_attrs='all')\n",
        "            image = torch.sigmoid(dr.texture(self.albedo.unsqueeze(0), texc, uv_da=texc_db)) # [1, H, W, 3]\n",
        "\n",
        "        image = image.view(1, h, w, 3)\n",
        "        # image = dr.antialias(image, rast, v_clip, f).clamp(0, 1)\n",
        "        image = image.squeeze(0).permute(2, 0, 1).contiguous() # [3, H, W]\n",
        "        image = alpha * image + (1 - alpha)\n",
        "\n",
        "        return image, alpha\n",
        "\n",
        "    def fit_mesh(self, iters=2048, resolution=512, decimate_target=5e4):\n",
        "\n",
        "        self.opt.output_size = resolution\n",
        "\n",
        "        # init mesh from nerf\n",
        "        grid_size = 256\n",
        "        sigmas = np.zeros([grid_size, grid_size, grid_size], dtype=np.float32)\n",
        "\n",
        "        S = 128\n",
        "        density_thresh = 10\n",
        "\n",
        "        X = torch.linspace(-1, 1, grid_size).split(S)\n",
        "        Y = torch.linspace(-1, 1, grid_size).split(S)\n",
        "        Z = torch.linspace(-1, 1, grid_size).split(S)\n",
        "\n",
        "        for xi, xs in enumerate(X):\n",
        "            for yi, ys in enumerate(Y):\n",
        "                for zi, zs in enumerate(Z):\n",
        "                    xx, yy, zz = torch.meshgrid(xs, ys, zs, indexing='ij')\n",
        "                    pts = torch.cat([xx.reshape(-1, 1), yy.reshape(-1, 1), zz.reshape(-1, 1)], dim=-1) # [S, 3]\n",
        "                    val = self.get_density(pts.to(self.device))\n",
        "                    sigmas[xi * S: xi * S + len(xs), yi * S: yi * S + len(ys), zi * S: zi * S + len(zs)] = val.reshape(len(xs), len(ys), len(zs)).detach().cpu().numpy() # [S, 1] --> [x, y, z]\n",
        "\n",
        "        print(f'[INFO] marching cubes thresh: {density_thresh} ({sigmas.min()} ~ {sigmas.max()})')\n",
        "\n",
        "        vertices, triangles = mcubes.marching_cubes(sigmas, density_thresh)\n",
        "        vertices = vertices / (grid_size - 1.0) * 2 - 1\n",
        "        \n",
        "        # clean\n",
        "        vertices = vertices.astype(np.float32)\n",
        "        triangles = triangles.astype(np.int32)\n",
        "        vertices, triangles = clean_mesh(vertices, triangles, remesh=True, remesh_size=0.01)\n",
        "        if triangles.shape[0] > decimate_target:\n",
        "            vertices, triangles = decimate_mesh(vertices, triangles, decimate_target, optimalplacement=False)\n",
        "        \n",
        "        self.v = torch.from_numpy(vertices).contiguous().float().to(self.device)\n",
        "        self.f = torch.from_numpy(triangles).contiguous().int().to(self.device)\n",
        "        self.deform = nn.Parameter(torch.zeros_like(self.v)).to(self.device)\n",
        "\n",
        "        # fit mesh from gs\n",
        "        lr_factor = 1\n",
        "        optimizer = torch.optim.Adam([\n",
        "            {'params': self.encoder.parameters(), 'lr': 1e-3 * lr_factor},\n",
        "            {'params': self.mlp.parameters(), 'lr': 1e-3 * lr_factor},\n",
        "            {'params': self.deform, 'lr': 1e-4},\n",
        "        ])\n",
        "\n",
        "        print(f\"[INFO] fitting mesh...\")\n",
        "        pbar = tqdm.trange(iters)\n",
        "        for i in pbar:\n",
        "\n",
        "            ver = np.random.randint(-10, 10)\n",
        "            hor = np.random.randint(-180, 180)\n",
        "            rad = self.opt.cam_radius # np.random.uniform(1, 2)\n",
        "\n",
        "            pose = orbit_camera(ver, hor, rad)\n",
        "            \n",
        "            image_gt, alpha_gt = self.render_gs(pose)\n",
        "            image_pred, alpha_pred = self.render_mesh(pose)\n",
        "\n",
        "            loss_mse = F.mse_loss(image_pred, image_gt) + 0.1 * F.mse_loss(alpha_pred, alpha_gt)\n",
        "            # loss_lap = laplacian_smooth_loss(self.v + self.deform, self.f)\n",
        "            loss_normal = normal_consistency(self.v + self.deform, self.f)\n",
        "            loss_offsets = (self.deform ** 2).sum(-1).mean()\n",
        "            loss = loss_mse + 0.001 * loss_normal + 0.1 * loss_offsets\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # remesh periodically\n",
        "            if i > 0 and i % 512 == 0:\n",
        "                vertices = (self.v + self.deform).detach().cpu().numpy()\n",
        "                triangles = self.f.detach().cpu().numpy()\n",
        "                vertices, triangles = clean_mesh(vertices, triangles, remesh=True, remesh_size=0.01)\n",
        "                if triangles.shape[0] > decimate_target:\n",
        "                    vertices, triangles = decimate_mesh(vertices, triangles, decimate_target, optimalplacement=False)\n",
        "                self.v = torch.from_numpy(vertices).contiguous().float().to(self.device)\n",
        "                self.f = torch.from_numpy(triangles).contiguous().int().to(self.device)\n",
        "                self.deform = nn.Parameter(torch.zeros_like(self.v)).to(self.device)\n",
        "                lr_factor *= 0.5\n",
        "                optimizer = torch.optim.Adam([\n",
        "                    {'params': self.encoder.parameters(), 'lr': 1e-3 * lr_factor},\n",
        "                    {'params': self.mlp.parameters(), 'lr': 1e-3 * lr_factor},\n",
        "                    {'params': self.deform, 'lr': 1e-4},\n",
        "                ])\n",
        "\n",
        "            pbar.set_description(f\"MSE = {loss_mse.item():.6f}\")\n",
        "        \n",
        "        # last clean\n",
        "        vertices = (self.v + self.deform).detach().cpu().numpy()\n",
        "        triangles = self.f.detach().cpu().numpy()\n",
        "        vertices, triangles = clean_mesh(vertices, triangles, remesh=False)\n",
        "        self.v = torch.from_numpy(vertices).contiguous().float().to(self.device)\n",
        "        self.f = torch.from_numpy(triangles).contiguous().int().to(self.device)\n",
        "        self.deform = nn.Parameter(torch.zeros_like(self.v).to(self.device))\n",
        "        \n",
        "        print(f\"[INFO] finished fitting mesh!\")\n",
        "    \n",
        "    # uv mesh refine\n",
        "    def fit_mesh_uv(self, iters=512, resolution=512, texture_resolution=1024, padding=2):\n",
        "\n",
        "        self.opt.output_size = resolution\n",
        "\n",
        "        # unwrap uv\n",
        "        print(f\"[INFO] uv unwrapping...\")\n",
        "        mesh = Mesh(v=self.v, f=self.f, albedo=None, device=self.device)\n",
        "        mesh.auto_normal()\n",
        "        mesh.auto_uv()\n",
        "\n",
        "        self.vt = mesh.vt\n",
        "        self.ft = mesh.ft\n",
        "\n",
        "        # render uv maps\n",
        "        h = w = texture_resolution\n",
        "        uv = mesh.vt * 2.0 - 1.0 # uvs to range [-1, 1]\n",
        "        uv = torch.cat((uv, torch.zeros_like(uv[..., :1]), torch.ones_like(uv[..., :1])), dim=-1) # [N, 4]\n",
        "\n",
        "        rast, _ = dr.rasterize(self.glctx, uv.unsqueeze(0), mesh.ft, (h, w)) # [1, h, w, 4]\n",
        "        xyzs, _ = dr.interpolate(mesh.v.unsqueeze(0), rast, mesh.f) # [1, h, w, 3]\n",
        "        mask, _ = dr.interpolate(torch.ones_like(mesh.v[:, :1]).unsqueeze(0), rast, mesh.f) # [1, h, w, 1]\n",
        "\n",
        "        # masked query \n",
        "        xyzs = xyzs.view(-1, 3)\n",
        "        mask = (mask > 0).view(-1)\n",
        "        \n",
        "        albedo = torch.zeros(h * w, 3, device=self.device, dtype=torch.float32)\n",
        "\n",
        "        if mask.any():\n",
        "            print(f\"[INFO] querying texture...\")\n",
        "\n",
        "            xyzs = xyzs[mask] # [M, 3]\n",
        "\n",
        "            # batched inference to avoid OOM\n",
        "            batch = []\n",
        "            head = 0\n",
        "            while head < xyzs.shape[0]:\n",
        "                tail = min(head + 640000, xyzs.shape[0])\n",
        "                batch.append(torch.sigmoid(self.mlp(self.encoder(xyzs[head:tail]))).float())\n",
        "                head += 640000\n",
        "\n",
        "            albedo[mask] = torch.cat(batch, dim=0)\n",
        "        \n",
        "        albedo = albedo.view(h, w, -1)\n",
        "        mask = mask.view(h, w)\n",
        "        albedo = uv_padding(albedo, mask, padding)\n",
        "\n",
        "        # optimize texture\n",
        "        self.albedo = nn.Parameter(inverse_sigmoid(albedo)).to(self.device)\n",
        "        \n",
        "        optimizer = torch.optim.Adam([\n",
        "            {'params': self.albedo, 'lr': 1e-3},\n",
        "        ])\n",
        "\n",
        "        print(f\"[INFO] fitting mesh texture...\")\n",
        "        pbar = tqdm.trange(iters)\n",
        "        for i in pbar:\n",
        "\n",
        "            # shrink to front view as we care more about it...\n",
        "            ver = np.random.randint(-5, 5)\n",
        "            hor = np.random.randint(-15, 15)\n",
        "            rad = self.opt.cam_radius # np.random.uniform(1, 2)\n",
        "            \n",
        "            pose = orbit_camera(ver, hor, rad)\n",
        "            \n",
        "            image_gt, alpha_gt = self.render_gs(pose)\n",
        "            image_pred, alpha_pred = self.render_mesh(pose)\n",
        "\n",
        "            loss_mse = F.mse_loss(image_pred, image_gt)\n",
        "            loss = loss_mse\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pbar.set_description(f\"MSE = {loss_mse.item():.6f}\")\n",
        "        \n",
        "        print(f\"[INFO] finished fitting mesh texture!\")\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def export_mesh(self, path):\n",
        "        \n",
        "        mesh = Mesh(v=self.v, f=self.f, vt=self.vt, ft=self.ft, albedo=torch.sigmoid(self.albedo), device=self.device)\n",
        "        mesh.auto_normal()\n",
        "        mesh.write(path)\n",
        "\n",
        "\n",
        "opt = tyro.cli(AllConfigs)\n",
        "\n",
        "# load a saved ply and convert to mesh\n",
        "assert opt.test_path.endswith('.ply'), '--test_path must be a .ply file saved by infer.py'\n",
        "\n",
        "converter = Converter(opt).cuda()\n",
        "converter.fit_nerf()\n",
        "converter.fit_mesh()\n",
        "converter.fit_mesh_uv()\n",
        "converter.export_mesh(opt.test_path.replace('.ply', '.glb'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
